{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ec10c95-a221-4048-bea7-d290042bfd73",
   "metadata": {},
   "source": [
    "#### Fundamentals of Machine learning Engineering < Inspirration for this lecture was gotten from Daniel Bouke >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565c21af-e21a-4f84-8ed9-a8942814da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7503f8-85e9-487a-84f2-d7e2aea3251d",
   "metadata": {},
   "source": [
    "### Creating a tensor\n",
    "\n",
    "To create a tensor in Pytorch we use torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae81333-2045-4f2e-9d3f-5f551901cd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "# Scalars: A single number\n",
    "scalar = torch.tensor(5)\n",
    "print(scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de8d0b68-6401-4466-89b7-20847271149e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(scalar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "564a226e-3148-4595-a216-0752368f6394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Vectors: 1-D tensor (array of numbers)\n",
    "vector = torch.tensor([1, 2, 3, 4])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eed7275-8639-4271-9a8d-95a065a29a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8c51c2-cbfb-49a8-b6b3-66e817f1fbe8",
   "metadata": {},
   "source": [
    "### Demonstrating the effect of Dimention on Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "592ad4dd-3203-42c8-89b3-9a3912d02c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 4, 8]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor\n",
    "TENSOR = torch.tensor([[1,2,3],[3,4,8]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4133dfd4-1fd9-4008-90a6-2b26137c7a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of TENSOR\n",
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef330983-d401-444a-8aa3-c5760cfd3f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Matrices: 2-D tensor (table of numbers)\n",
    "MATRIX = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(MATRIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92a0dd1a-5979-4e7a-87ec-742902713f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35a41d12-7657-41b1-b344-ca09357b77e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n"
     ]
    }
   ],
   "source": [
    "# Tensors: A generalization of matrices to higher dimensions\n",
    "TENSOR_3D = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print(TENSOR_3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee2f8e88-a214-4bef-aac6-3ea59e016165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(TENSOR_3D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab39a9-162f-4fe4-b45d-305e832923e2",
   "metadata": {},
   "source": [
    "### Tensors Dimension and Tensor shape\n",
    "\n",
    "`Tensor dimension:` The dimension of a tensor refers to the number of axes or indices needed to uniquely identify an element in the tensor. It describes the rank or order of the tensor.\n",
    "\n",
    "`Tensor shape:` The shape of a tensor describes the size of each dimension. It tells you how many elements exist along each axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77d44566-4667-4de3-af22-e108f9f4a832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efcf4a45-e961-445c-9b06-7cdd48fcf643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e742e7cd-aa24-4e78-a375-3faf8a41fe88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f672d0f-9a82-4c13-a3d4-db554e5eb871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a66275-e2a1-4286-bd2d-92b5c7b5b521",
   "metadata": {},
   "source": [
    "![example of different tensor dimensions](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e6851-82c3-49a6-a4fc-b8fb7b08f566",
   "metadata": {},
   "source": [
    "### Random Tensors\n",
    "\n",
    "`torch.rand()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42cdf37c-b989-4922-b79c-7c82b56bdf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3605, 0.2013, 0.9608, 0.0709],\n",
       "         [0.6172, 0.5798, 0.5258, 0.0320],\n",
       "         [0.3960, 0.9133, 0.7098, 0.9093]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(size=(3, 4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c7112e-fd58-42b9-9c8b-2a859187bc4f",
   "metadata": {},
   "source": [
    "### Zeros and Ones tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "106a0f93-1da8-4d27-95e9-8bd5b9236c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(4, 4))\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "381a6c3f-69d5-46c7-87cc-317662816c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624162b-cbaa-43d0-b8ef-53def3128fa8",
   "metadata": {},
   "source": [
    "### Creating a range\n",
    "\n",
    "Sometimes you might want a range of numbers, such as 1 to 10 or 0 to 100.\n",
    "\n",
    "You can use `torch.arange(start, end, step)` to do so.\n",
    "\n",
    "Where:\n",
    "* `start` = start of range (e.g. 0)\n",
    "* `end` = end of range (e.g. 10)\n",
    "* `step` = how many steps in between each valuethe future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "994f6c89-6b7d-4175-8432-685ca1ed7e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a range of values 0 to 10\n",
    "image = torch.arange(start=0, end=10, step=1)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aef7eb4-3e1b-4dbe-98db-03e81a59c49e",
   "metadata": {},
   "source": [
    "### Creating tensor like\n",
    "\n",
    "Sometimes you might want one tensor of a certain type with the same shape as another tensor.\n",
    "\n",
    "For example, a tensor of all zeros with the same shape as a previous tensor. \n",
    "\n",
    "To do so you can use `torch.zeros_like(input)` or `torch.ones_like(input)` which return a tensor filled with zeros or ones in the same shape as the `input` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2110feb-d713-4495-8446-fd21f5434bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a tensor of zero's similar any tensor of choice\n",
    "ten_zeros = torch.zeros_like(input=image)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0086cd6e-6588-470a-89d4-0298cca246ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a tensor of one's similar any tensor of choice\n",
    "ten_zeros = torch.ones_like(image)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c87948-4326-452c-b2b0-7bea4cb77c31",
   "metadata": {},
   "source": [
    "# Precision in Machine Learning Engineering (Computer Science)\n",
    "\n",
    "In computer science, **precision** refers to the level of detail or exactness with which a value is represented, particularly in numerical computations. It deals with how exact a representation or computation is, often in terms of the number of significant digits or bits used to represent data. The concept applies more broadly to any system that deals with data accuracy. \n",
    "\n",
    "`The base 10 -> base 2 analogy`\n",
    "\n",
    "## Precision in Data representation\n",
    "\n",
    "#### 1. **8-bit Precision**:\n",
    "   - **Range**: If you're dealing with an 8-bit unsigned integer, it can represent values from `0` to `255` (i.e., \\(2^8 = 256\\) values). In the case of signed integers (which include negative numbers), the range is from `-128` to `127` for 8-bit integers.\n",
    "   - **Application**: 8-bit precision is used in situations where minimal storage is needed, like grayscale pixel values (0–255) in images or basic integer operations in microcontrollers.\n",
    "\n",
    "#### 2. **16-bit Precision**:\n",
    "   - **Range**: For unsigned integers, 16 bits can represent values from `0` to `65,535` (i.e., \\(2^{16} = 65,536\\)). For signed integers, the range is from `-32,768` to `32,767`.\n",
    "   - **Application**: This is common in older video games, audio processing, or where you need more precision but still want to limit memory usage. For floating-point numbers, 16-bit (half-precision) is often used in machine learning models to save memory and computational power.\n",
    "\n",
    "#### 3. **32-bit Precision**:\n",
    "   - **Range**: A 32-bit unsigned integer can represent values from `0` to `4,294,967,295` (i.e., \\(2^{32} = 4,294,967,296\\)). A signed 32-bit integer ranges from `-2,147,483,648` to `2,147,483,647`.\n",
    "   - **Application**: 32-bit precision is common for general-purpose computing. In floating-point terms, a 32-bit float is called **single precision** and has about 7 significant decimal digits of precision. This is commonly used in scientific calculations and graphics.\n",
    "\n",
    "#### 4. **64-bit Precision**:\n",
    "   - **Range**: For unsigned integers, 64 bits can represent values from `0` to \\(2^{64} - 1\\), which is a very large number. Signed integers range from \\(-2^{63}\\) to \\(2^{63} - 1\\).\n",
    "   - **Application**: 64-bit precision is used in modern systems for large data sets, scientific computing, and databases. In floating-point terms, **double precision** (64-bit) allows for about 15–16 significant decimal digits of precision, offering much higher accuracy for numerical computations.\n",
    "\n",
    "## **Precision in Floating-Point Representation**:\n",
    "The concept of precision becomes even more important in floating-point representations (such as IEEE-754 standard). These representations are split into a **mantissa** (significant digits) and **exponent** (magnitude), and the precision depends on how many bits are allocated to the mantissa.\n",
    "\n",
    "#### 1. **Precision in Floating-Point Arithmetic:**\n",
    "   - **Single Precision** (32-bit floating point): Typically uses 32 bits to represent a number, providing approximately 7 decimal digits of precision. This is the default precision in many systems and programming environments.\n",
    "     - Example: `1.2345678` (7 significant digits)\n",
    "   - **Double Precision** (64-bit floating point): Uses 64 bits, providing approximately 15–16 decimal digits of precision, allowing for much more accurate calculations compared to single precision.\n",
    "     - Example: `1.23456789012345` (15 significant digits)\n",
    "   - **Half Precision** (16-bit floating point): Uses 16 bits and provides about 3–4 decimal digits of precision. It is primarily used to save memory and computational power, often in deep learning models.\n",
    "     - Example: `1.23` (3 significant digits)\n",
    "\n",
    "\n",
    "### Summary:\n",
    "- **Higher bit depths (16-bit, 32-bit, 64-bit, etc.)** offer **greater precision** because they allow more bits to represent the number, which provides a finer granularity of values.\n",
    "- Precision determines the **range** and **accuracy** of the representation, meaning how small or large numbers can be, as well as how many significant digits can be captured.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc2c283-7480-4236-bbce-ee11143ac6c9",
   "metadata": {},
   "source": [
    "### Creating Tensors with specific data type\n",
    "\n",
    "This can come in handy for some kind of data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a2c5829-7a95-4418-be84-e6b1507edd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "float_tensor0 = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "print(float_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e19bb5cb-770b-4e9c-8e5a-1ba00c09a865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "float_tensor1 = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float16)\n",
    "print(float_tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f737eb1d-38ac-4f99-921e-a9065dc90c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "float_tensor2 = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float64)\n",
    "print(float_tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fca1aaf-ae9d-46fb-b660-90196ac22ff8",
   "metadata": {},
   "source": [
    "## Tensor datatypes -> Precision : The consept of Precision is caption in ML as datatypes\n",
    "#### Default datatype -> conversion from one datatype to anothern do so using the `dtype` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22a53c91-e117-4256-bb2f-5ac3ed8c0ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # What device is your tensor on, CPU or GPU\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b058381-3da8-492c-9c7e-801e954d898f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.float16) # torch.half would also work\n",
    "\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a6522-6474-4c44-919a-91d329e6960d",
   "metadata": {},
   "source": [
    "## Getting information from tensors (attributes)\n",
    "\n",
    "Once you've created tensors (or someone else or a PyTorch module has created them for you), you might want to get some information from them.\n",
    "\n",
    "We've seen these before but three of the most common attributes you'll want to find out about tensors are:\n",
    "* `shape` - what shape is the tensor? (some operations require specific shape rules)\n",
    "* `dtype` - what datatype are the elements within the tensor stored in?\n",
    "* `device` - what device is the tensor stored on? (usually GPU or CPU)\n",
    "\n",
    "Let's create a random tensor and find out details about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2091cc80-89ea-4e05-8257-f8c3ed516b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_tensor1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15290d6e-0748-499f-8c18-e7a33e4decc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_tensor2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0533d48-b72b-494c-84c5-8c9ee2bca46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8339, 0.0147, 0.6937, 0.5385],\n",
      "        [0.2688, 0.3754, 0.4160, 0.2265],\n",
      "        [0.3727, 0.4525, 0.2498, 0.0350]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "# Find out details about it\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1b0ce9-180a-4556-80e1-3090270705f0",
   "metadata": {},
   "source": [
    "## Manipulating tensors (tensor operations)\n",
    "\n",
    "In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.\n",
    "\n",
    "A model learns by investigating those tensors and performing a series of operations (could be 1,000,000s+) on tensors to create a representation of the patterns in the input data.\n",
    "\n",
    "These operations are often a wonderful dance between:\n",
    "* Addition\n",
    "* Substraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix multiplication\n",
    "\n",
    "And that's it. Sure there are a few more here and there but these are the basic building blocks of neural networks.\n",
    "\n",
    "Stacking these building blocks in the right way, you can create the most sophisticated of neural networks (just like lego!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445c6f8b-f6f3-496d-82fa-020bb3eedf22",
   "metadata": {},
   "source": [
    "### Basic operations\n",
    "\n",
    "Let's start with a few of the fundamental operations, addition (`+`), subtraction (`-`), mutliplication (`*`).\n",
    "\n",
    "They work just as you think they would."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77239616-ba2a-46eb-aef4-40772a808aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of values and add a number to it\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2cb25a8-448a-4135-b8de-ed192dca05c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply it by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20e62d41-5e33-46fc-ad1b-33702f249640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also use torch functions\n",
    "torch.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10dec987-6c53-4a8b-8906-f2545799d7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensors don't change unless reassigned\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca82e2-827e-4526-b7d4-93d235b8ae18",
   "metadata": {},
   "source": [
    "### Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7caa11bf-a0df-439d-b0b5-0f2f884a9d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract and reassign\n",
    "tensor = tensor - 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "683381ce-f425-44d7-be96-468d6a58a83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add and reassign\n",
    "tensor = tensor + 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf83a131-d339-4a34-9526-7a7f3aed592c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication (each element multiplies its equivalent, index 0->0, 1->1, 2->2)\n",
    "print(tensor, \"*\", tensor)\n",
    "print(\"Equals:\", tensor * tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692d997e-9f34-4e27-8060-17698e655f8c",
   "metadata": {},
   "source": [
    "### Matrix multiplication (Dot product)\n",
    "\n",
    "One of the most common operations in machine learning and deep learning algorithms (like neural networks) is [matrix multiplication](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e50d477f-685f-4bf9-98ce-d58814d32367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19, 22],\n",
       "        [43, 50]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define two matrices (2D tensors)\n",
    "matrix_a = torch.tensor([[1, 2], [3, 4]])\n",
    "matrix_b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "# Perform matrix multiplication using torch.matmul()\n",
    "result = torch.matmul(matrix_a, matrix_b)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebf070d0-4bf6-4b6a-b49e-37b76d19558d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 30,  24,  18],\n",
       "        [ 84,  69,  54],\n",
       "        [138, 114,  90]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define two matrices (3x3 tensors)\n",
    "matrix_a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "matrix_b = torch.tensor([[9, 8, 7], [6, 5, 4], [3, 2, 1]])\n",
    "\n",
    "# Perform matrix multiplication using torch.matmul()\n",
    "result = torch.matmul(matrix_a, matrix_b)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fa42921-3f3c-4698-b73a-664b98c1b5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13, 16]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define a 1x2 matrix and a 2x2 matrix\n",
    "matrix_a = torch.tensor([[1, 2]])  # 1x2 matrix\n",
    "matrix_b = torch.tensor([[3, 4], [5, 6]])  # 2x2 matrix\n",
    "\n",
    "# Perform matrix multiplication\n",
    "result = torch.matmul(matrix_a, matrix_b)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3aa0f4b7-d784-49c4-8bb3-8772a51bfa7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m matrix_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m], [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m10\u001b[39m], [\u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m12\u001b[39m]])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Attempt to perform matrix multiplication\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix_b\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define two (3, 2) matrices\n",
    "matrix_a = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "matrix_b = torch.tensor([[7, 8], [9, 10], [11, 12]])\n",
    "\n",
    "# Attempt to perform matrix multiplication\n",
    "result = torch.matmul(matrix_a, matrix_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b753d833-6b00-4bd4-9c9a-7377705e54d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x3 and 2x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m matrix_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m], [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m12\u001b[39m]])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Attempt to perform matrix multiplication\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix_b\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x3 and 2x3)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define two (2, 3) matrices\n",
    "matrix_a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "matrix_b = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "\n",
    "# Attempt to perform matrix multiplication\n",
    "result = torch.matmul(matrix_a, matrix_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c268d8b-a7be-4cb5-9995-c983e2e62138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17, 39])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define a matrix (2D tensor)\n",
    "matrix_a = torch.tensor([[1, 2], [3, 4]])\n",
    "\n",
    "# Define a vector (1D tensor)\n",
    "vector_b = torch.tensor([5, 6])\n",
    "\n",
    "# Perform matrix-vector multiplication using torch.matmul()\n",
    "result = torch.matmul(matrix_a, vector_b)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89282a92-a3a5-4adc-95f5-82d164ea4883",
   "metadata": {},
   "source": [
    "PyTorch implements matrix multiplication functionality in the [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html) method.\n",
    "\n",
    "The main two rules for matrix multiplication to remember are:\n",
    "\n",
    "1. The **inner dimensions** must match:\n",
    "  * `(3, 2) @ (3, 2)` won't work\n",
    "  * `(2, 3) @ (3, 2)` will work\n",
    "  * `(3, 2) @ (2, 3)` will work\n",
    "2. The resulting matrix has the shape of the **outer dimensions**:\n",
    " * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    " * `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
    "3. Matrix to vector multiplication\n",
    " * `matrix (m x n)` * `vector n length` will work\n",
    "     \n",
    "   If you have a matrix \\( A \\) of shape \\((m \\times n)\\) and a vector \\( v \\) of length \\( n \\), their matrix-vector multiplication results in a vector of length \\( m \\). Each element of the resulting vector is the dot product of a row of the matrix with the vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a100a-bf84-482f-9627-ca9957692e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8752623f-7e81-4e5c-9111-1805c1a4d954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchstudio",
   "language": "python",
   "name": "pytorchstudio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
